{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Weekly-Project-BBC Articles.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8btHNo7H5Cf"
      },
      "source": [
        "# Organize ML projects with Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yK9CuWlH5Ch"
      },
      "source": [
        "While Machine Learning is powerful, people often overestimate it: apply machine learning to your project, and all your problems will be solved. In reality, it's not this simple. To be effective, one needs to organize the work very well. In this notebook, we will walkthrough practical aspects of a ML project. To look at the big picture, let's start with a checklist below. It should work reasonably well for most ML projects, but make sure to adapt it to your needs:\n",
        "\n",
        "1. **Define the scope of work and objective**\n",
        "    * How is your solution be used?\n",
        "    * How should performance be measured? Are there any contraints?\n",
        "    * How would the problem be solved manually?\n",
        "    * List the available assumptions, and verify if possible.\n",
        "    \n",
        "    \n",
        "2. **Get the data**\n",
        "    * Document where you can get that data\n",
        "    * Store data in a workspace you can easily access\n",
        "    * Convert the data to a format you can easily manipulate\n",
        "    * Check the overview (size, type, sample, description, statistics)\n",
        "    * Data cleaning\n",
        "    \n",
        "    \n",
        "3. **EDA & Data transformation**\n",
        "    * Study each attribute and its characteristics (missing values, type of distribution, usefulness)\n",
        "    * Visualize the data\n",
        "    * Study the correlations between attributes\n",
        "    * Feature selection, Feature Engineering, Feature scaling\n",
        "    * Write functions for all data transformations\n",
        "    \n",
        "    \n",
        "4. **Train models**\n",
        "    * Automate as much as possible\n",
        "    * Train promising models quickly using standard parameters. Measure and compare their performance\n",
        "    * Analyze the errors the models make\n",
        "    * Shortlist the top three of five most promising models, preferring models that make different types of errors.\n",
        "\n",
        "\n",
        "5. **Fine-tunning**\n",
        "    * Treat data transformation choices as hyperparameters, expecially when you are not sure about them (e.g., replace missing values with zeros or with the median value)\n",
        "    * Unless there are very few hyperparameter value to explore, prefer random search over grid search.\n",
        "    * Try ensemble methods\n",
        "    * Test your final model on the test set to estimate the generalizaiton error. Don't tweak your model again, you would start overfitting the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofeuKevOH5Ch"
      },
      "source": [
        "## Example: Articles categorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2NSUqUEH5Ci"
      },
      "source": [
        "### Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GttlMG-H5Cj"
      },
      "source": [
        "Build a model to determine the categories of articles. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwbjWOG1H5Ck"
      },
      "source": [
        "### Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWq7xex_H5Ck"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9W7Hzt2H5Cp"
      },
      "source": [
        "bbc = pd.read_csv('https://raw.githubusercontent.com/dhminh1024/practice_datasets/master/bbc-text.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teb1QvD1H5Cs",
        "outputId": "ebaebb96-9d22-4838-a191-c1598b12ad92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "bbc.sample(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>business</td>\n",
              "      <td>card fraudsters  targeting web  new safeguards...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003</th>\n",
              "      <td>business</td>\n",
              "      <td>mild winter drives us oil down 6% us oil price...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>politics</td>\n",
              "      <td>csa  could close   says minister ministers wou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024</th>\n",
              "      <td>politics</td>\n",
              "      <td>blair blasts tory spending plans tony blair ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>784</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>&amp;#163;1.8m indecency fine for viacom media gia...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           category                                               text\n",
              "199        business  card fraudsters  targeting web  new safeguards...\n",
              "2003       business  mild winter drives us oil down 6% us oil price...\n",
              "128        politics  csa  could close   says minister ministers wou...\n",
              "2024       politics  blair blasts tory spending plans tony blair ha...\n",
              "784   entertainment  &#163;1.8m indecency fine for viacom media gia..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBW_Sg2RH5Cy",
        "outputId": "958afb76-152d-40a4-8670-70c364dec6d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "bbc.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2225 entries, 0 to 2224\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   category  2225 non-null   object\n",
            " 1   text      2225 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 34.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh3VRY5Zxmw6",
        "outputId": "6a64e1bf-c177-4db3-a555-ab511d944a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "# Your code here\n",
        "bbc"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2220</th>\n",
              "      <td>business</td>\n",
              "      <td>cars pull down us retail figures us retail sal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2221</th>\n",
              "      <td>politics</td>\n",
              "      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2222</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>rem announce new glasgow concert us band rem h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2223</th>\n",
              "      <td>politics</td>\n",
              "      <td>how political squabbles snowball it s become c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2224</th>\n",
              "      <td>sport</td>\n",
              "      <td>souness delight at euro progress boss graeme s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2225 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           category                                               text\n",
              "0              tech  tv future in the hands of viewers with home th...\n",
              "1          business  worldcom boss  left books alone  former worldc...\n",
              "2             sport  tigers wary of farrell  gamble  leicester say ...\n",
              "3             sport  yeading face newcastle in fa cup premiership s...\n",
              "4     entertainment  ocean s twelve raids box office ocean s twelve...\n",
              "...             ...                                                ...\n",
              "2220       business  cars pull down us retail figures us retail sal...\n",
              "2221       politics  kilroy unveils immigration policy ex-chatshow ...\n",
              "2222  entertainment  rem announce new glasgow concert us band rem h...\n",
              "2223       politics  how political squabbles snowball it s become c...\n",
              "2224          sport  souness delight at euro progress boss graeme s...\n",
              "\n",
              "[2225 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBPZMdhKdi2G",
        "outputId": "4201a3b0-6a21-4505-d32f-1cca15e7905c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "bbc[\"category\"].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sport            511\n",
              "business         510\n",
              "politics         417\n",
              "tech             401\n",
              "entertainment    386\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQkqONYodr3_",
        "outputId": "ce6726b6-32f4-47d9-d2e2-819ff4c44fe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "bbc.isnull().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "category    0\n",
              "text        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ7if0Tdd5QV",
        "outputId": "417c17ff-2b19-414d-92e0-84a04029a2fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5QTISj0DARL",
        "outputId": "3413ab3a-bc5c-4ba0-9652-dc97dcf614cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "stop_words"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2qZrTwteJe8",
        "outputId": "c08802d4-fe07-4f0f-bf8d-550739580bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "vocab = Counter()\n",
        "for twit in bbc.text:\n",
        "    for word in twit.split(' '):\n",
        "        vocab[word] += 1\n",
        "\n",
        "vocab.most_common(20)\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "vocab_reduced = Counter()\n",
        "\n",
        "for w, c in vocab.items():\n",
        "    if not w in stop_words:\n",
        "        vocab_reduced[w]=c\n",
        "\n",
        "vocab_reduced.most_common(20)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 65553),\n",
              " ('said', 5072),\n",
              " ('-', 3195),\n",
              " ('mr', 2992),\n",
              " ('would', 2574),\n",
              " ('also', 2154),\n",
              " ('people', 1970),\n",
              " ('new', 1957),\n",
              " ('us', 1786),\n",
              " ('one', 1705),\n",
              " ('could', 1509),\n",
              " ('said.', 1499),\n",
              " ('year', 1396),\n",
              " ('last', 1380),\n",
              " ('first', 1277),\n",
              " ('.', 1171),\n",
              " ('two', 1161),\n",
              " ('government', 1085),\n",
              " ('world', 1076),\n",
              " ('uk', 993)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPAirKVkeSX5"
      },
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "def preprocessor(text):\n",
        "    # Remove HTML markup\n",
        "    text = strip_html(text)\n",
        "    \n",
        "    # Save emoticons for later appending\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "    \n",
        "    # Remove any non-word character and append the emoticons,\n",
        "    # removing the nose character for standarization. Convert to lower case\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQFcuIEweim2"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "# Your code here\n",
        "porter = PorterStemmer()\n",
        "\n",
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvwOeaN4enm_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = bbc['text']\n",
        "y = bbc['category']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=102)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9ahWxXmev7E"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words=stop_words,\n",
        "                        tokenizer=tokenizer_porter,\n",
        "                        preprocessor=preprocessor)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fikTcfaae9W5",
        "outputId": "8d8d0e2f-6ea6-499e-dca4-28605492aa54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbm = Pipeline([('vect', tfidf),\n",
        "                ('clf', LGBMClassifier())])\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=<function preprocessor at 0x7f54204e0488>,\n",
              "                                 smooth_idf=True,\n",
              "                                 stop_words=['i', 'me', 'my', 'myself', '...\n",
              "                 LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
              "                                colsample_bytree=1.0, importance_type='split',\n",
              "                                learning_rate=0.1, max_depth=-1,\n",
              "                                min_child_samples=20, min_child_weight=0.001,\n",
              "                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,\n",
              "                                num_leaves=31, objective=None,\n",
              "                                random_state=None, reg_alpha=0.0,\n",
              "                                reg_lambda=0.0, silent=True, subsample=1.0,\n",
              "                                subsample_for_bin=200000, subsample_freq=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTdZ2QC-feMA",
        "outputId": "19bcefec-f025-4759-a734-d0d16e50fd4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Using Test dataset to evaluate model\n",
        "# classification_report\n",
        "# confusion matrix\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Now apply those above metrics to evaluate your model\n",
        "# Your code here\n",
        "predictions = clf.predict(X_test)\n",
        "print('accuracy:',accuracy_score(y_test,predictions))\n",
        "print('confusion matrix:\\n',confusion_matrix(y_test,predictions))\n",
        "print('classification report:\\n',classification_report(y_test,predictions))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.9752808988764045\n",
            "confusion matrix:\n",
            " [[87  0  1  0  2]\n",
            " [ 0 90  1  1  0]\n",
            " [ 1  0 83  1  0]\n",
            " [ 0  0  0 98  1]\n",
            " [ 2  0  1  0 76]]\n",
            "classification report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     business       0.97      0.97      0.97        90\n",
            "entertainment       1.00      0.98      0.99        92\n",
            "     politics       0.97      0.98      0.97        85\n",
            "        sport       0.98      0.99      0.98        99\n",
            "         tech       0.96      0.96      0.96        79\n",
            "\n",
            "     accuracy                           0.98       445\n",
            "    macro avg       0.97      0.97      0.97       445\n",
            " weighted avg       0.98      0.98      0.98       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkIQR7W6CVJJ"
      },
      "source": [
        "wrong_predicted_text = X_test[y_test != predictions]\n",
        "wrong_predictions = predictions[y_test != predictions]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUCrwxnHD5JX",
        "outputId": "4bee8e1e-d500-482d-dce9-57e7f3dabd23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "pd.DataFrame({\"Text\":wrong_predicted_text,\"Predictions\":wrong_predictions})"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>547</th>\n",
              "      <td>ink helps drive democracy in asia the kyrgyz r...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2201</th>\n",
              "      <td>ban on forced retirement under 65 employers wi...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2072</th>\n",
              "      <td>hatfield executives go on trial engineering fi...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1200</th>\n",
              "      <td>tv calls after carroll error spurs boss martin...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>card fraudsters  targeting web  new safeguards...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1799</th>\n",
              "      <td>peace demo appeal rejected peace protestors ha...</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>us hacker breaks into t-mobile a man is facing...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1127</th>\n",
              "      <td>my memories of marley...  to mark the 60th ann...</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1567</th>\n",
              "      <td>brookside creator s channel 4 bid the creator ...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1674</th>\n",
              "      <td>google shares fall as staff sell shares in goo...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>anti-spam laws bite spammer hard the net s sel...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text Predictions\n",
              "547   ink helps drive democracy in asia the kyrgyz r...    politics\n",
              "2201  ban on forced retirement under 65 employers wi...    politics\n",
              "2072  hatfield executives go on trial engineering fi...    business\n",
              "1200  tv calls after carroll error spurs boss martin...        tech\n",
              "199   card fraudsters  targeting web  new safeguards...        tech\n",
              "1799  peace demo appeal rejected peace protestors ha...       sport\n",
              "993   us hacker breaks into t-mobile a man is facing...    business\n",
              "1127  my memories of marley...  to mark the 60th ann...       sport\n",
              "1567  brookside creator s channel 4 bid the creator ...    politics\n",
              "1674  google shares fall as staff sell shares in goo...        tech\n",
              "727   anti-spam laws bite spammer hard the net s sel...    business"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}